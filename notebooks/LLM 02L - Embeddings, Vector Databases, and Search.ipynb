{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02L - Embeddings, Vector Databases, and Search\n",
    "\n",
    "\n",
    "In this lab, we will apply the text vectorization, search, and question answering workflow that you learned in the demo. The dataset we will use this time will be on talk titles and sessions from [Data + AI Summit 2023](https://www.databricks.com/dataaisummit/). \n",
    "\n",
    "![Dolly](https://files.training.databricks.com/images/llm/dolly_small.png)\n",
    "\n",
    "### Learning Objectives\n",
    "1. Learn how to use Chroma to store your embedding vectors and conduct similarity search\n",
    "1. Use OpenAI GPT-3.5 to generate response to your prompt\n",
    "\n",
    "`pip install chromadb==0.3.21 tiktoken==0.3.3`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_paths_datasets = \"../data\"\n",
    "assert Path(DA_paths_datasets).exists()\n",
    "\n",
    "\n",
    "DA_paths_user_db = \"../userdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added parent directory /Users/mjboothaus/code/github/mjboothaus/large-language-models-da to PYTHONPATH\n"
     ]
    }
   ],
   "source": [
    "from notebook_helper import (\n",
    "    notebook_add_parent_dir_to_path,\n",
    ")\n",
    "\n",
    "notebook_add_parent_dir_to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing lab testing framework.\n"
     ]
    }
   ],
   "source": [
    "from Includes.Test_Framework import dbTestQuestion2_1, dbTestQuestion2_2, dbTestQuestion2_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daistalks_23.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls $DA_paths_datasets/dais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI in Healthcare</td>\n",
       "      <td>This session will explore the transformative i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural Language Processing: From Theory to Pr...</td>\n",
       "      <td>Dive into the world of Natural Language Proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reinforcement Learning in Autonomous Systems</td>\n",
       "      <td>Discover how reinforcement learning techniques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethical Considerations in AI Development</td>\n",
       "      <td>As AI continues to evolve, ethical considerati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep Learning for Computer Vision</td>\n",
       "      <td>Explore the world of deep learning and compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI-powered Fraud Detection</td>\n",
       "      <td>Fraud detection is a critical challenge for or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generative Adversarial Networks: Creating Real...</td>\n",
       "      <td>Learn how generative adversarial networks (GAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explainable AI: Interpreting Black Box Models</td>\n",
       "      <td>Interpretability is a key factor in deploying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI for Financial Services</td>\n",
       "      <td>This session will showcase how AI is revolutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reinventing Customer Experience with AI</td>\n",
       "      <td>Discover how AI is reshaping the customer expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                   AI in Healthcare   \n",
       "1  Natural Language Processing: From Theory to Pr...   \n",
       "2       Reinforcement Learning in Autonomous Systems   \n",
       "3           Ethical Considerations in AI Development   \n",
       "4                  Deep Learning for Computer Vision   \n",
       "5                         AI-powered Fraud Detection   \n",
       "6  Generative Adversarial Networks: Creating Real...   \n",
       "7      Explainable AI: Interpreting Black Box Models   \n",
       "8                          AI for Financial Services   \n",
       "9            Reinventing Customer Experience with AI   \n",
       "\n",
       "                                            Abstract  \n",
       "0  This session will explore the transformative i...  \n",
       "1  Dive into the world of Natural Language Proces...  \n",
       "2  Discover how reinforcement learning techniques...  \n",
       "3  As AI continues to evolve, ethical considerati...  \n",
       "4  Explore the world of deep learning and compute...  \n",
       "5  Fraud detection is a critical challenge for or...  \n",
       "6  Learn how generative adversarial networks (GAN...  \n",
       "7  Interpretability is a key factor in deploying ...  \n",
       "8  This session will showcase how AI is revolutio...  \n",
       "9  Discover how AI is reshaping the customer expe...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dais_pdf = pd.read_parquet(f\"{DA_paths_datasets}/dais/dais23_talks.parquet\")\n",
    "display(dais_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: AI in Healthcare\n",
      "                Abstract:  This session will explore the transformative impact of artificial intelligence in the healthcare industry. Artificial intelligence (AI) has the potential to revolutionize healthcare by improving diagnostics, enabling personalized treatment plans, and enhancing patient monitoring. Join us as we delve into the latest advancements in medical imaging analysis, predictive analytics for disease management, and AI-powered clinical decision support systems. Discover how AI algorithms can analyze vast amounts of patient data, identify patterns, and provide valuable insights for healthcare professionals. Learn about the challenges and opportunities of implementing AI in healthcare and the potential for improving patient outcomes and reducing healthcare costs.\n"
     ]
    }
   ],
   "source": [
    "dais_pdf[\"full_text\"] = dais_pdf.apply(\n",
    "    lambda row: f\"\"\"Title: {row[\"Title\"]}\n",
    "                Abstract:  {row[\"Abstract\"]}\"\"\".strip(),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "print(dais_pdf.iloc[0][\"full_text\"])\n",
    "\n",
    "texts = dais_pdf[\"full_text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI in Healthcare</td>\n",
       "      <td>This session will explore the transformative i...</td>\n",
       "      <td>Title: AI in Healthcare\\n                Abstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natural Language Processing: From Theory to Pr...</td>\n",
       "      <td>Dive into the world of Natural Language Proces...</td>\n",
       "      <td>Title: Natural Language Processing: From Theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reinforcement Learning in Autonomous Systems</td>\n",
       "      <td>Discover how reinforcement learning techniques...</td>\n",
       "      <td>Title: Reinforcement Learning in Autonomous Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethical Considerations in AI Development</td>\n",
       "      <td>As AI continues to evolve, ethical considerati...</td>\n",
       "      <td>Title: Ethical Considerations in AI Developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep Learning for Computer Vision</td>\n",
       "      <td>Explore the world of deep learning and compute...</td>\n",
       "      <td>Title: Deep Learning for Computer Vision\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI-powered Fraud Detection</td>\n",
       "      <td>Fraud detection is a critical challenge for or...</td>\n",
       "      <td>Title: AI-powered Fraud Detection\\n           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generative Adversarial Networks: Creating Real...</td>\n",
       "      <td>Learn how generative adversarial networks (GAN...</td>\n",
       "      <td>Title: Generative Adversarial Networks: Creati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explainable AI: Interpreting Black Box Models</td>\n",
       "      <td>Interpretability is a key factor in deploying ...</td>\n",
       "      <td>Title: Explainable AI: Interpreting Black Box ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI for Financial Services</td>\n",
       "      <td>This session will showcase how AI is revolutio...</td>\n",
       "      <td>Title: AI for Financial Services\\n            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reinventing Customer Experience with AI</td>\n",
       "      <td>Discover how AI is reshaping the customer expe...</td>\n",
       "      <td>Title: Reinventing Customer Experience with AI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                   AI in Healthcare   \n",
       "1  Natural Language Processing: From Theory to Pr...   \n",
       "2       Reinforcement Learning in Autonomous Systems   \n",
       "3           Ethical Considerations in AI Development   \n",
       "4                  Deep Learning for Computer Vision   \n",
       "5                         AI-powered Fraud Detection   \n",
       "6  Generative Adversarial Networks: Creating Real...   \n",
       "7      Explainable AI: Interpreting Black Box Models   \n",
       "8                          AI for Financial Services   \n",
       "9            Reinventing Customer Experience with AI   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  This session will explore the transformative i...   \n",
       "1  Dive into the world of Natural Language Proces...   \n",
       "2  Discover how reinforcement learning techniques...   \n",
       "3  As AI continues to evolve, ethical considerati...   \n",
       "4  Explore the world of deep learning and compute...   \n",
       "5  Fraud detection is a critical challenge for or...   \n",
       "6  Learn how generative adversarial networks (GAN...   \n",
       "7  Interpretability is a key factor in deploying ...   \n",
       "8  This session will showcase how AI is revolutio...   \n",
       "9  Discover how AI is reshaping the customer expe...   \n",
       "\n",
       "                                           full_text  \n",
       "0  Title: AI in Healthcare\\n                Abstr...  \n",
       "1  Title: Natural Language Processing: From Theor...  \n",
       "2  Title: Reinforcement Learning in Autonomous Sy...  \n",
       "3  Title: Ethical Considerations in AI Developmen...  \n",
       "4  Title: Deep Learning for Computer Vision\\n    ...  \n",
       "5  Title: AI-powered Fraud Detection\\n           ...  \n",
       "6  Title: Generative Adversarial Networks: Creati...  \n",
       "7  Title: Explainable AI: Interpreting Black Box ...  \n",
       "8  Title: AI for Financial Services\\n            ...  \n",
       "9  Title: Reinventing Customer Experience with AI...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dais_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Set up Chroma and create collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: ../userdb\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "chroma_client = chromadb.Client(\n",
    "    Settings(\n",
    "        chroma_db_impl=\"duckdb+parquet\",\n",
    "        persist_directory=DA_paths_user_db,  # this is an optional argument. If you don't supply this, the data will be ephemeral\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value of `my_talks` to the `collection_name` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"my_talks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collection: 'my_talks'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# If you have created the collection before, you need to delete the collection first\n",
    "if len(chroma_client.list_collections()) > 0 and collection_name in [chroma_client.list_collections()[0].name]:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "else:\n",
    "    print(f\"Creating collection: '{collection_name}'\")\n",
    "    talks_collection = chroma_client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mPASSED\u001b[0m: All tests passed for lesson2, question1\n",
      "\u001b[32mRESULTS RECORDED\u001b[0m: Click `Submit` when all questions are completed to log the results.\n"
     ]
    }
   ],
   "source": [
    "dbTestQuestion2_1(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "[Add](https://docs.trychroma.com/reference/Collection#add) data to the collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "talks_collection.add(\n",
    "    documents=<FILL_IN>,\n",
    "    ids=<FILL_IN>\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your answer. DO NOT MODIFY THIS CELL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Test NOT passed: The collection should be non-empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dbTestQuestion2_2(talks_collection)\n",
      "File \u001b[0;32m~/code/github/mjboothaus/large-language-models-da/Includes/Test_Framework.py:118\u001b[0m, in \u001b[0;36mdbTestQuestion2_2\u001b[0;34m(talks_collection)\u001b[0m\n\u001b[1;32m    114\u001b[0m userhome_for_testing \u001b[39m=\u001b[39m getUsernameFromEnv(lesson)\n\u001b[1;32m    116\u001b[0m \u001b[39massert\u001b[39;00m  \u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(talks_collection)) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<class \u001b[39m\u001b[39m'\u001b[39m\u001b[39mchromadb.api.models.Collection.Collection\u001b[39m\u001b[39m'\u001b[39m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTest NOT passed: Result should be of type `chromadb.api.models.Collection.Collection`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 118\u001b[0m \u001b[39massert\u001b[39;00m talks_collection\u001b[39m.\u001b[39mcount() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTest NOT passed: The collection should be non-empty.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m questionPassed(userhome_for_testing, lesson, question)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Test NOT passed: The collection should be non-empty."
     ]
    }
   ],
   "source": [
    "dbTestQuestion2_2(talks_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "[Query](https://docs.trychroma.com/reference/Collection#query) for relevant documents. If you are looking for talks related to language models, your query texts could be `language models`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoIndexException",
     "evalue": "Index not found, please create an instance before querying",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoIndexException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m results \u001b[39m=\u001b[39m talks_collection\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     query_texts\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlanguage models\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     n_results\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mjboothaus/code/github/mjboothaus/large-language-models-da/notebooks/tmp5.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(json\u001b[39m.\u001b[39mdumps(results, indent\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m))\n",
      "File \u001b[0;32m~/code/github/mjboothaus/large-language-models-da/.venv/lib/python3.10/site-packages/chromadb/api/models/Collection.py:202\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m where_document \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     where_document \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_query(\n\u001b[1;32m    203\u001b[0m     collection_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    204\u001b[0m     query_embeddings\u001b[39m=\u001b[39;49mquery_embeddings,\n\u001b[1;32m    205\u001b[0m     n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[1;32m    206\u001b[0m     where\u001b[39m=\u001b[39;49mwhere,\n\u001b[1;32m    207\u001b[0m     where_document\u001b[39m=\u001b[39;49mwhere_document,\n\u001b[1;32m    208\u001b[0m     include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m    209\u001b[0m )\n",
      "File \u001b[0;32m~/code/github/mjboothaus/large-language-models-da/.venv/lib/python3.10/site-packages/chromadb/api/local.py:247\u001b[0m, in \u001b[0;36mLocalAPI._query\u001b[0;34m(self, collection_name, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_query\u001b[39m(\n\u001b[1;32m    239\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    240\u001b[0m     collection_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     include: Include \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmetadatas\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdistances\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     uuids, distances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_db\u001b[39m.\u001b[39;49mget_nearest_neighbors(\n\u001b[1;32m    248\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    249\u001b[0m         where\u001b[39m=\u001b[39;49mwhere,\n\u001b[1;32m    250\u001b[0m         where_document\u001b[39m=\u001b[39;49mwhere_document,\n\u001b[1;32m    251\u001b[0m         embeddings\u001b[39m=\u001b[39;49mquery_embeddings,\n\u001b[1;32m    252\u001b[0m         n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    255\u001b[0m     include_embeddings \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include\n\u001b[1;32m    256\u001b[0m     include_documents \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include\n",
      "File \u001b[0;32m~/code/github/mjboothaus/large-language-models-da/.venv/lib/python3.10/site-packages/chromadb/db/clickhouse.py:520\u001b[0m, in \u001b[0;36mClickhouse.get_nearest_neighbors\u001b[0;34m(self, where, where_document, embeddings, n_results, collection_name, collection_uuid)\u001b[0m\n\u001b[1;32m    517\u001b[0m     ids \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    519\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index(collection_uuid)\n\u001b[0;32m--> 520\u001b[0m uuids, distances \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_nearest_neighbors(embeddings, n_results, ids)\n\u001b[1;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m uuids, distances\n",
      "File \u001b[0;32m~/code/github/mjboothaus/large-language-models-da/.venv/lib/python3.10/site-packages/chromadb/db/index/hnswlib.py:223\u001b[0m, in \u001b[0;36mHnswlib.get_nearest_neighbors\u001b[0;34m(self, query, k, ids)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_nearest_neighbors\u001b[39m(\u001b[39mself\u001b[39m, query, k, ids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m         \u001b[39mraise\u001b[39;00m NoIndexException(\u001b[39m\"\u001b[39m\u001b[39mIndex not found, please create an instance before querying\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    225\u001b[0m     \u001b[39m# Check dimensionality\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_dimensionality(query)\n",
      "\u001b[0;31mNoIndexException\u001b[0m: Index not found, please create an instance before querying"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "results = talks_collection.query(query_texts=\"language models\", n_results=4)\n",
    "\n",
    "print(json.dumps(results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_3(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Load a language model and create a [pipeline](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Pick a model from HuggingFace that can generate text\n",
    "model_id = \"<FILL_IN>\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "lm_model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"<FILL_IN>\",\n",
    "    model=lm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    device_map=\"auto\",\n",
    "    handle_long_generation=\"hole\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_4(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Prompt engineering for question answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Come up with a question that you need the LLM assistant to help you with\n",
    "# A sample question is \"Help me find sessions related to XYZ\" \n",
    "# Note: Your \"XYZ\" should be related to the query you passed in Question 3. \n",
    "question = \"<FILL_IN>\"\n",
    "\n",
    "# Provide all returned similar documents from the cell above below\n",
    "context = <FILL_IN>\n",
    "\n",
    "# Feel free to be creative how you construct the prompt. You can use the demo notebook as a jumpstart reference.\n",
    "# You can also provide more requirements in the text how you want the answers to look like.\n",
    "# Example requirement: \"Recommend top-5 relevant sessions for me to attend.\"\n",
    "prompt_template = <FILL_IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_5(question, context, prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 \n",
    "\n",
    "Submit query for language model to generate response.\n",
    "\n",
    "Hint: If you run into the error `index out of range in self`, make sure to check out this [documentation page](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TextGenerationPipeline.__call__.handle_long_generation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_response = pipe(<FILL_IN>)\n",
    "print(lm_response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your answer. DO NOT MODIFY THIS CELL.\n",
    "\n",
    "dbTestQuestion2_6(lm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output isn't exactly helpful. Head on to using OpenAI to try out GPT-3.5 instead! \n",
    "\n",
    "## OPTIONAL (Non-Graded): Use OpenAI models for Q/A\n",
    "\n",
    "For this section to work, you need to generate an Open AI key. \n",
    "\n",
    "Steps:\n",
    "1. You need to [create an account](https://platform.openai.com/signup) on OpenAI. \n",
    "2. Generate an OpenAI [API key here](https://platform.openai.com/account/api-keys). \n",
    "\n",
    "Note: OpenAI does not have a free option, but it gives you $5 as credit. Once you have exhausted your $5 credit, you will need to add your payment method. You will be [charged per token usage](https://openai.com/pricing). **IMPORTANT**: It's crucial that you keep your OpenAI API key to yourself. If others have access to your OpenAI key, they will be able to charge their usage to your account! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<FILL IN>\"\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to estimate how much it would cost to use OpenAI, you can use `tiktoken` library from OpenAI to get the number of tokens from your prompt.\n",
    "\n",
    "We will be using `gpt-3.5-turbo` since it's the most economical option at ($0.002/1k tokens), as of May 2023. GPT-4 charges $0.04/1k tokens. The following code block below is referenced from OpenAI's documentation on [\"Managing tokens\"](https://platform.openai.com/docs/guides/chat/managing-tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "price_token = 0.002\n",
    "encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "cost_to_run = len(encoder.encode(prompt_template)) / 1000 * price_token\n",
    "print(f\"It would take roughly ${round(cost_to_run, 5)} to run this prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't have to create a new vector database again. We can just send our `context` from above to OpenAI. We will use their chat completion API to interact with `GPT-3.5-turbo`. You can refer to their [documentation here](https://platform.openai.com/docs/guides/chat).\n",
    "\n",
    "Something interesting is that OpenAI models use the system message to help their assistant to be more accurate. From OpenAI's [docs](https://platform.openai.com/docs/guides/chat/introduction):\n",
    "\n",
    "> Future models will be trained to pay stronger attention to system messages. The system message helps set the behavior of the assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": <FILL_IN>},\n",
    "    ],\n",
    "    temperature=0, # 0 makes outputs deterministic; The closer the value is to 1, the more random the outputs are for each time you re-run.\n",
    ")\n",
    "\n",
    "print(gpt35_response.choices[0][\"message\"][\"content\"])\n",
    "\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(gpt35_response.choices[0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check how many tokens OpenAI has used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt35_response[\"usage\"][\"total_tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The results are noticeably much better compared to when using Hugging Face's GPT-2! It didn't get stuck in the text generation, but the sessions recommended are not all relevant to pandas either. You can further do more prompt engineering to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
